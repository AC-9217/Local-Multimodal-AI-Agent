# 使用文档

本项目是一个基于 Python 的本地多模态 AI 智能助手，支持文献的语义搜索与自动分类，以及基于文本描述的图像检索。

## 1. 环境准备


```bash
conda create -n exp2 python=3.10
pip install -r requestment.txt
```
值得注意的是，我确实是直接安装requestment.txt的，但里没指定版本号。
实验在2025.12.15进行，如果间隔时间不长，建议直接使用pip install -r requestment.txt。
否则建议使用pip install -r requestment_2.txt。这是在我使用 pip freeze > requirements_2.txt导出的。

**网络特别提示：**
如果在下载模型时遇到网络问题，请设置 Hugging Face 镜像环境变量。
**目前项目代码中已配置自动设置 HF_ENDPOINT 环境变量为 https://hf-mirror.com，无需手动设置。**
如果仍有问题，可以尝试手动设置：
```bash
export HF_ENDPOINT=https://hf-mirror.com&&
```

**备注：上面的命令只能说大概率有效，不如魔法好使。**

## 2. 核心功能与命令

本项目可以使用命令行操作，也可以通过 UI 界面进行操作。

+ 使用如下命令直接启动UI。UI都是中文界面，我就不细讲怎么使用了。如有疑问参考本目录下的”演示视频.mp4“或者UI目录下的readme文件
```bash
python .\UI\main_ui.py
```
+ 命令行操作的教程在下面↓

### 2.1 添加与分类论文 (add_paper)

将新的 PDF 论文添加到系统中，自动提取文本、建立索引，并可选地将其分类移动到对应文件夹。

**命令格式：**
```bash
python main.py add_paper <PDF路径> [选项]
```

**参数说明：**
- `path`: PDF 文件的路径（必填）。
- `--topics`: 预定义的主题列表，用于自动分类（如 "CV,NLP,RL"）。
- `--move`: 如果指定，根据分类结果将文件移动到 `data/papers/<Topic>` 目录下。
- `--no-index`: 如果指定，仅处理文件但不更新向量数据库。

**示例：**
```bash
# 添加论文，自动分类为 CV 或 NLP，并移动文件
python main.py add_paper my_paper.pdf --topics "CV,NLP" --move

# 仅建立索引，不移动文件
python main.py add_paper my_paper.pdf
```

---

### 2.2 搜索论文 (search_paper)

使用自然语言问题搜索已索引的论文。支持返回相关文件列表和具体的文本片段（含页码）。

**命令格式：**
```bash
python main.py search_paper "<查询语句>" [选项]
```

**参数说明：**
- `query`: 搜索问题或关键词（必填）。
- `--top_k`: 返回结果的数量（默认为 5）。
- `--return_snippets`: 是否返回具体的文本片段与页码。
- `--return_files`: 是否返回相关的文件列表（默认为 True）。

**示例：**
```bash
# 搜索关于 Transformer 的论文，返回前 3 个结果
python main.py search_paper "Transformer architecture" --top_k 3

# 搜索并查看具体的文本片段（带页码）
python main.py search_paper "What is attention mechanism?" --return_snippets
```

---

### 2.3 批量整理论文 (batch_organize)

对指定目录下的所有 PDF 文件进行批量扫描、分类、移动和索引。适合整理现有的混乱文件夹。
支持**混合整理模式**：优先匹配 `data/papers` 中现有的主题文件夹，如果没有匹配到合适的主题，则自动进行聚类并生成新主题。

**命令格式：**
```bash
python main.py batch_organize --root <目录路径> [选项]
```

**参数说明：**
- `--root`: 要扫描的根目录路径（必填）。
- `--topics`: 预定义的主题列表（可选）。
  - 如果提供了主题列表（如 `"CV,NLP"`），则仅使用这些主题进行分类。
  - **如果不提供此参数**，系统将自动检测现有主题并进行混合智能整理（优先匹配现有主题，否则自动聚类）。

**示例：**
```bash
# 自动整理：优先匹配现有主题，未匹配的自动聚类
python main.py batch_organize --root data/papers

# 强制使用指定主题进行整理
python main.py batch_organize --root data/papers --topics "CV,NLP,RL"
```

---

### 2.4 建立图像索引 (index_images)

扫描指定目录下的图片文件，使用 CLIP 模型提取特征并建立索引，以便进行“以文搜图”。

**命令格式：**
```bash
python main.py index_images [选项]
```

**参数说明：**
- `--dir`: 指定要索引的图片目录。如果不指定，默认使用配置文件中的 `data/images`。

**示例：**
```bash
# 索引 data/images 下的所有图片
python main.py index_images

# 索引特定目录
python main.py index_images --dir /path/to/my/photos
```

---

### 2.5 以文搜图 (search_image)

使用自然语言描述查找最匹配的本地图片。

**命令格式：**
```bash
python main.py search_image "<描述>" [选项]
```

**参数说明：**
- `query`: 图片内容的文本描述（必填）。
- `--top_k`: 返回结果的数量（默认为 5）。

**示例：**
```bash
# 查找包含红色物体的图片
python main.py search_image "something red"

# 查找海边日落的图片
python main.py search_image "sunset at the beach"
```

## 3. 数据与配置

- **配置文件**: `agent/config.py`
  - 默认文本模型 `sentence-transformers/paraphrase-multilingual-mpnet-base-v2` (768维)，支持多语言且性能更强。
  - 默认图像模型 **`xlm-roberta-large-ViT-H-14`** (权重 `frozen_laion5b_s13b_b90k`)。
    - **特点**：1024维高精度向量，**原生支持中文**等多语言检索，基于 Huge 级别模型，检索效果更佳。
  - 可修改数据存储路径（默认在 `data/` 目录下）。
- **数据目录**:
  - `data/papers`: 存放论文文件。
  - `data/images`: 存放图片文件。
  - `data/index`: 存放 ChromaDB 向量数据库文件。

